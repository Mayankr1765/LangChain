from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
from langchain_text_splitters import CharacterTextSplitter
from langchain_community.llms import HuggingFaceHub
from langchain.chains import RetrievalQA

# 1. HR Policy Text Sample
hr_policy = """
Company Leave Policy:
- Employees are entitled to 20 paid leaves per year.
- Sick leave requires a doctor's note if it exceeds 2 days.
- Unused leave can be carried forward up to 10 days.

Work from Home Policy:
- Employees can work from home up to 2 days per week.
- During probation, work from home is not allowed.

Reimbursement Policy:
- Travel expenses must be pre-approved by the reporting manager.
- Reimbursements should be claimed within 30 days of the expense.
"""

# 2. Create LangChain Documents
docs = [Document(page_content=hr_policy)]

# 3. Split Documents into Chunks
splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=30)
split_docs = splitter.split_documents(docs)

# 4. Load Embedding Model
embedding_model = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

# 5. Create FAISS Vector DB
db = FAISS.from_documents(split_docs, embedding_model)

# 6. Load LLM from HuggingFace Hub
llm = HuggingFaceHub(
    repo_id="google/flan-t5-base",
    huggingfacehub_api_token="sample_token",
    model_kwargs={"temperature": 0.3, "max_length": 512}
)


# 7. Create QA Chain with Retriever
retriever = db.as_retriever()
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

# response = llm.invoke("What is the leave policy?")
# print(response)



# 8. Chat Loop
print("ðŸ¤– HR Bot (LangChain + HuggingFace) is ready! Type 'exit' to quit.\n")
while True:
    query = input("You: ")
    if query.lower() in ["exit", "quit"]:
        break
    answer = qa_chain.run(query)
    print("ðŸ¤– HR Bot:", answer, "\n")
